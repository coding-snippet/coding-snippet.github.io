[
  {
    "objectID": "coding-styles/functions.html",
    "href": "coding-styles/functions.html",
    "title": "Functional",
    "section": "",
    "text": "Following the DRY principle (don’t repeat yourself), functional programming allows the coder to reuse certain chunks of code. The input values are called arguments, while to actual logic performed by the function happens in the body. Functions also create a local environment.\n\n\n\nR\n\n\n\n\nThere are 4 types of functions in R.\n\n\n\n\na = \"start_a\"\nb = \"start_b\"\n\ndo_sth &lt;- function() {\n  a = 1\n  b = 2\n  print(paste(a,b))\n}\n\ndo_sth_else &lt;- function() {\n  a = 1\n  print(paste(a,b))\n}\n\ndo_sth()\n\n[1] \"1 2\"\n\ndo_sth_else()\n\n[1] \"1 start_b\"\n\nprint(paste(a, b))\n\n[1] \"start_a start_b\"\n\n\n\n\n\nFunctions can be grouped by adding them to a list.\n\nfun &lt;- list(\n  dog = function() print(\"bark\"),\n  cat = function() print(\"meow\"),\n  fox = function() print(\"What does the fox say?\")\n)\n\nfun$fox()\n\n[1] \"What does the fox say?\"\n\n\n\n\n\n\n\nPythonR\n\n\n\nimport pandas as pd\n\ndef get_product_quantity(product):\n  \"\"\"\n  Function to get the total quantity of a specific product from orders table.\n  \n  Arguments:\n  product: A string specifying the product name.\n  \n  Returns:\n  The total quantity of the specified product.\n  \"\"\"\n  merged_data = pd.merge(orders, products, on=\"product_id\", how=\"inner\")\n  filtered_data = merged_data[merged_data['product_name'] == product]\n  quantity_sum = filtered_data['quantity'].sum()\n  return quantity_sum\n\nget_product_quantity(\"field\")\n\n46.0\n\n\n\n\n\nget_product_quantity &lt;- function(product) {\n  result &lt;- orders %&gt;%\n    inner_join(products, by = \"product_id\") %&gt;% \n    filter(product_name == product) %&gt;% \n    summarize(sum = sum(quantity)) %&gt;% \n    pull(sum) \n  return(result)\n}\n\nget_product_quantity(\"field\")\n\n[1] 46"
  },
  {
    "objectID": "coding-styles/functions.html#functional-programming",
    "href": "coding-styles/functions.html#functional-programming",
    "title": "Functional",
    "section": "",
    "text": "Following the DRY principle (don’t repeat yourself), functional programming allows the coder to reuse certain chunks of code. The input values are called arguments, while to actual logic performed by the function happens in the body. Functions also create a local environment.\n\n\n\nR\n\n\n\n\nThere are 4 types of functions in R.\n\n\n\n\na = \"start_a\"\nb = \"start_b\"\n\ndo_sth &lt;- function() {\n  a = 1\n  b = 2\n  print(paste(a,b))\n}\n\ndo_sth_else &lt;- function() {\n  a = 1\n  print(paste(a,b))\n}\n\ndo_sth()\n\n[1] \"1 2\"\n\ndo_sth_else()\n\n[1] \"1 start_b\"\n\nprint(paste(a, b))\n\n[1] \"start_a start_b\"\n\n\n\n\n\nFunctions can be grouped by adding them to a list.\n\nfun &lt;- list(\n  dog = function() print(\"bark\"),\n  cat = function() print(\"meow\"),\n  fox = function() print(\"What does the fox say?\")\n)\n\nfun$fox()\n\n[1] \"What does the fox say?\"\n\n\n\n\n\n\n\nPythonR\n\n\n\nimport pandas as pd\n\ndef get_product_quantity(product):\n  \"\"\"\n  Function to get the total quantity of a specific product from orders table.\n  \n  Arguments:\n  product: A string specifying the product name.\n  \n  Returns:\n  The total quantity of the specified product.\n  \"\"\"\n  merged_data = pd.merge(orders, products, on=\"product_id\", how=\"inner\")\n  filtered_data = merged_data[merged_data['product_name'] == product]\n  quantity_sum = filtered_data['quantity'].sum()\n  return quantity_sum\n\nget_product_quantity(\"field\")\n\n46.0\n\n\n\n\n\nget_product_quantity &lt;- function(product) {\n  result &lt;- orders %&gt;%\n    inner_join(products, by = \"product_id\") %&gt;% \n    filter(product_name == product) %&gt;% \n    summarize(sum = sum(quantity)) %&gt;% \n    pull(sum) \n  return(result)\n}\n\nget_product_quantity(\"field\")\n\n[1] 46"
  },
  {
    "objectID": "data-wrangling/exporting_data.html",
    "href": "data-wrangling/exporting_data.html",
    "title": "Exporting data",
    "section": "",
    "text": "Excel/CSVs are a very handy format to transport (relatively) small amounts of data between stakeholders.\n\nPythonR\n\n\n\n#add code here\n\n\n\n\nlibrary(openxlsx)\nwb &lt;- createWorkbook()\nsheet &lt;- addWorksheet(wb, sheetName = \"my_sheet_name\")\nwriteData(wb, sheet, df, startCol = 1, startRow = 1)\nsaveWorkbook(wb,\n             file = \"path.xlsx\",\n             overwrite = TRUE)"
  },
  {
    "objectID": "data-wrangling/exporting_data.html#excel-files-and-csvs",
    "href": "data-wrangling/exporting_data.html#excel-files-and-csvs",
    "title": "Exporting data",
    "section": "",
    "text": "Excel/CSVs are a very handy format to transport (relatively) small amounts of data between stakeholders.\n\nPythonR\n\n\n\n#add code here\n\n\n\n\nlibrary(openxlsx)\nwb &lt;- createWorkbook()\nsheet &lt;- addWorksheet(wb, sheetName = \"my_sheet_name\")\nwriteData(wb, sheet, df, startCol = 1, startRow = 1)\nsaveWorkbook(wb,\n             file = \"path.xlsx\",\n             overwrite = TRUE)"
  },
  {
    "objectID": "data-wrangling/reading_data.html",
    "href": "data-wrangling/reading_data.html",
    "title": "Importing data",
    "section": "",
    "text": "Reading in data from various sources is one of the key skills to get a day of data wrangling started. There are tons of vanilla functions as well as cool packages to do the job."
  },
  {
    "objectID": "data-wrangling/reading_data.html#excel-files-and-csvs",
    "href": "data-wrangling/reading_data.html#excel-files-and-csvs",
    "title": "Importing data",
    "section": "Excel files and CSVs",
    "text": "Excel files and CSVs\nExcel/CSVs are a very handy format to transport (relatively) small amounts of data between stakeholders.\n\nPythonR\n\n\n\nimport pandas as pd\ndf = pd.read_excel(\"path.xlsx\", sheet_name=\"Sheet1\") # for Excels\ndf = pd.read_csv(\"path.csv\") # for comma separated\ndf = pd.read_csv(\"path.csv\", sep=';') # for semicolon separated\n\n\n\n\ndf &lt;- read_excel(\"path\", sheet = \"Sheet1\") # readxl package\ndf &lt;- read.csv(\"path\") # comma separated\ndf &lt;- read.csv2(\"path\") # semicolon separated"
  },
  {
    "objectID": "data-wrangling/loops.html",
    "href": "data-wrangling/loops.html",
    "title": "Loops",
    "section": "",
    "text": "for loops are probably the most used form of loops. A for loop iterates over iterable objects such as lists, vectors, sets and other data structures. In contrast to the while loop, the for loop is less prone to ending up in infinite loop and is therefore preferable. :::{{.callout-note}} Note, that for loops can often be replaced with the more sophisticated apply, sapply or lapply. :::\n\nPythonR\n\n\nIterate over the items in a list:\n\nx = [\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\"]\nfor i in x:\n    print(i)\n\nhello\nmy\nname\nis\neugen\nwhat's\nyour\nname?\n\n\nGet the index of the element using enumerate():\n\nx = [\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\"]\nfor i, value in enumerate(x):\n    print(f\"{i} {value}\")\n\n0 hello\n1 my\n2 name\n3 is\n4 eugen\n5 what's\n6 your\n7 name?\n\n\n\n\n\n\n\n\nCaution\n\n\n\nKeep in mind, that iterables start with the index 0 in python\n\n\nJump to next iteration using continue, exit the loop using break:\n\nx = [\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\"]\nfor i in x:\n    if i in [\"my\", \"name\", \"is\"]:\n        continue\n    else:\n        print(i)\n        if i == \"eugen\":\n            break\n\nhello\neugen\n\n\n\n\nIterate over the items in a vector:\n\nx = c(\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\")\nfor (i in x) {\n  print(i)\n}\n\n[1] \"hello\"\n[1] \"my\"\n[1] \"name\"\n[1] \"is\"\n[1] \"eugen\"\n[1] \"what's\"\n[1] \"your\"\n[1] \"name?\"\n\n\nGet the index of the element using seq_along():\n\nx = c(\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\")\nfor (i in seq_along(x)) { # always use seq_along instead of 1:length(x) or 1:nrow(df)\n  print(paste(i,x[i]))\n}\n\n[1] \"1 hello\"\n[1] \"2 my\"\n[1] \"3 name\"\n[1] \"4 is\"\n[1] \"5 eugen\"\n[1] \"6 what's\"\n[1] \"7 your\"\n[1] \"8 name?\"\n\n\n\n\n\n\n\n\nCaution\n\n\n\nKeep in mind, that iterables start with the index 1 in R.\n\n\nJump to next iteration using next, exit the loop using break:\n\nx = c(\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\")\nfor (i in x) {\n  if (i %in% c(\"my\", \"name\", \"is\")) {\n    next\n  } else {\n    print(i)\n    if (i == \"eugen\") break\n  }\n}\n\n[1] \"hello\"\n[1] \"eugen\""
  },
  {
    "objectID": "data-wrangling/loops.html#the-for-loop",
    "href": "data-wrangling/loops.html#the-for-loop",
    "title": "Loops",
    "section": "",
    "text": "for loops are probably the most used form of loops. A for loop iterates over iterable objects such as lists, vectors, sets and other data structures. In contrast to the while loop, the for loop is less prone to ending up in infinite loop and is therefore preferable. :::{{.callout-note}} Note, that for loops can often be replaced with the more sophisticated apply, sapply or lapply. :::\n\nPythonR\n\n\nIterate over the items in a list:\n\nx = [\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\"]\nfor i in x:\n    print(i)\n\nhello\nmy\nname\nis\neugen\nwhat's\nyour\nname?\n\n\nGet the index of the element using enumerate():\n\nx = [\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\"]\nfor i, value in enumerate(x):\n    print(f\"{i} {value}\")\n\n0 hello\n1 my\n2 name\n3 is\n4 eugen\n5 what's\n6 your\n7 name?\n\n\n\n\n\n\n\n\nCaution\n\n\n\nKeep in mind, that iterables start with the index 0 in python\n\n\nJump to next iteration using continue, exit the loop using break:\n\nx = [\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\"]\nfor i in x:\n    if i in [\"my\", \"name\", \"is\"]:\n        continue\n    else:\n        print(i)\n        if i == \"eugen\":\n            break\n\nhello\neugen\n\n\n\n\nIterate over the items in a vector:\n\nx = c(\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\")\nfor (i in x) {\n  print(i)\n}\n\n[1] \"hello\"\n[1] \"my\"\n[1] \"name\"\n[1] \"is\"\n[1] \"eugen\"\n[1] \"what's\"\n[1] \"your\"\n[1] \"name?\"\n\n\nGet the index of the element using seq_along():\n\nx = c(\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\")\nfor (i in seq_along(x)) { # always use seq_along instead of 1:length(x) or 1:nrow(df)\n  print(paste(i,x[i]))\n}\n\n[1] \"1 hello\"\n[1] \"2 my\"\n[1] \"3 name\"\n[1] \"4 is\"\n[1] \"5 eugen\"\n[1] \"6 what's\"\n[1] \"7 your\"\n[1] \"8 name?\"\n\n\n\n\n\n\n\n\nCaution\n\n\n\nKeep in mind, that iterables start with the index 1 in R.\n\n\nJump to next iteration using next, exit the loop using break:\n\nx = c(\"hello\", \"my\", \"name\", \"is\", \"eugen\", \"what's\", \"your\", \"name?\")\nfor (i in x) {\n  if (i %in% c(\"my\", \"name\", \"is\")) {\n    next\n  } else {\n    print(i)\n    if (i == \"eugen\") break\n  }\n}\n\n[1] \"hello\"\n[1] \"eugen\""
  },
  {
    "objectID": "data-wrangling/filtering.html",
    "href": "data-wrangling/filtering.html",
    "title": "Filtering",
    "section": "",
    "text": "Filtering dataframes is a crucial skill of any data scientist and there is probably the most used method in data wrangling."
  },
  {
    "objectID": "data-wrangling/filtering.html#filter-by-is-equal-to",
    "href": "data-wrangling/filtering.html#filter-by-is-equal-to",
    "title": "Filtering",
    "section": "Filter by “is equal to”",
    "text": "Filter by “is equal to”\nThe most basic form of filtering is by comparing a search term with the values of a column in a dataframe.\n\nPythonRSQL\n\n\n\nThe bracket notation\nThe first method is the classic syntax with the square brackets. Even though this method seems to be a bit from last century, it is the preferred method of many coders.\n\nimport pandas as pd\n\nfiltered_df = customers[customers.customer_name == 'Anthony Guerra']\nfiltered_df\n\n                            customer_id  ...                                            address\n0  8ab2552b-e4c9-471d-bdf1-ff6e225860e1  ...  963 Regina Bridge Apt. 279\\nPort Richard, NJ 4...\n\n[1 rows x 5 columns]\n\n\n\n\nThe query notation\nPandas offers a nice function that enables you to write queries in the following way:\n\nimport pandas as pd\n\nfiltered_df = customers.query('customer_name == \"Anthony Guerra\"')\nfiltered_df\n\n                            customer_id  ...                                            address\n0  8ab2552b-e4c9-471d-bdf1-ff6e225860e1  ...  963 Regina Bridge Apt. 279\\nPort Richard, NJ 4...\n\n[1 rows x 5 columns]\n\n\n\n\nThe loc function\nProvides the ability to filter dataframes by index names: df[row_name or filter,“column_name”].\n\nimport pandas as pd\n\nfiltered_df = customers.loc[customers.customer_name == \"Anthony Guerra\",] # comma not necessary\nfiltered_df\n\n                            customer_id  ...                                            address\n0  8ab2552b-e4c9-471d-bdf1-ff6e225860e1  ...  963 Regina Bridge Apt. 279\\nPort Richard, NJ 4...\n\n[1 rows x 5 columns]\n\n\n\n\nThe iloc function\nProvides the ability to filter dataframes by index: df[from:to,from:to].\n\nimport pandas as pd\n\nfiltered_df = customers.iloc[20:25,2:4]\nfiltered_df\n\n                        email         phone_number\n20      jeffrey71@example.com     001-582-898-9180\n21       jandrews@example.com  (652)154-8443x09491\n22        robin69@example.com           9724123889\n23         mary10@example.com           8598893292\n24  gonzaleznorma@example.org        (278)903-9109\n\n\n\n\n\n\nThe bracket notation\nThe first method is the classic syntax with the square brackets. Even though this method seems to be a bit from last century, it is the preferred method of many coders.\n\nfiltered_df = customers[customers$customer_name == 'Anthony Guerra',] # comma is necessary!\nfiltered_df\n\n# A tibble: 1 × 5\n  customer_id                          customer_name  email phone_number address\n  &lt;chr&gt;                                &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;  \n1 8ab2552b-e4c9-471d-bdf1-ff6e225860e1 Anthony Guerra jane… 659.461.7580 \"963 R…\n\n\n\n\nThe dplyr method\n\nfiltered_df &lt;- customers %&gt;% filter(customer_name == \"Anthony Guerra\")\nfiltered_df\n\n# A tibble: 1 × 5\n  customer_id                          customer_name  email phone_number address\n  &lt;chr&gt;                                &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;  \n1 8ab2552b-e4c9-471d-bdf1-ff6e225860e1 Anthony Guerra jane… 659.461.7580 \"963 R…\n\n\n\n\n\n\nselect\n  *\nfrom \n  customers\nwhere 0=0\n  and customer_name = 'Anthony Guerra';\n\n\n1 records\n\n\n\n\n\n\n\n\n\ncustomer_id\ncustomer_name\nemail\nphone_number\naddress\n\n\n\n\n8ab2552b-e4c9-471d-bdf1-ff6e225860e1\nAnthony Guerra\njanet90@example.net\n659.461.7580\n963 Regina Bridge Apt. 279\n\n\nPort Richard, NJ 42041"
  },
  {
    "objectID": "data-wrangling/filtering.html#filter-by-is-empty",
    "href": "data-wrangling/filtering.html#filter-by-is-empty",
    "title": "Filtering",
    "section": "Filter by “is empty”",
    "text": "Filter by “is empty”\nBe honest, everyone hates empty values. However, we still have to deal with them!\n\nPythonRSQL\n\n\n\nDrop rows where at least one column value is NA\n\n# add code here\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'A': [1, None, 3, None, None],\n    'B': [5, None, None, None, None],\n    'C': ['x', 'y', None, 'z', None]\n})\n\nfiltered_df = df.dropna()\nprint(filtered_df)\n\n     A    B  C\n0  1.0  5.0  x\n\n\n\n\nDrop rows where whole row is None\n\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'A': [1, None, 3, None, None],\n    'B': [5, None, None, None, None],\n    'C': ['x', 'y', None, 'z', None]\n})\n\nfiltered_df = df.dropna(how='all')\nprint(filtered_df)\n\n     A    B     C\n0  1.0  5.0     x\n1  NaN  NaN     y\n2  3.0  NaN  None\n3  NaN  NaN     z\n\n\n\n\n\n\nDrop rows where at least one column value is NA\n\nlibrary(dplyr)\nlibrary(tidyr)\n\ndf &lt;- data.frame(\n  A = c(1, NA, 3, NA, NA),\n  B = c(5, NA, NA, NA, NA),\n  C = c(\"x\", \"y\", NA, \"z\", NA)\n)\n\ndf %&gt;% drop_na()\n\n  A B C\n1 1 5 x\n\n\n\n\nDrop rows where whole row is NA\n\nlibrary(dplyr)\nlibrary(tidyr)\n\ndf &lt;- data.frame(\n  A = c(1, NA, 3, NA, NA),\n  B = c(5, NA, NA, NA, NA),\n  C = c(\"x\", \"y\", NA, \"z\", NA)\n)\n\ndf %&gt;% filter_all(any_vars(!is.na(.)))\n\n   A  B    C\n1  1  5    x\n2 NA NA    y\n3  3 NA &lt;NA&gt;\n4 NA NA    z\n\n\n\n\n\n\nDrop rows where at least one column value is NULL\n\nselect\n  *\nfrom\n  schema.table\nwhere 0=0\n  and A is not null \n  and B is not null \n  and C is not null;\n\n\n\nDrop rows where all column values are NULL\n\nselect\n  *\nfrom\n  schema.table\nwhere 0=0\n  coalesce(A, B, C) is not null;"
  },
  {
    "objectID": "data-wrangling/faking.html",
    "href": "data-wrangling/faking.html",
    "title": "Faking data",
    "section": "",
    "text": "R\n\n\n\nx = runif(n = 1000, min = 0, max = 200)\nboxplot(x)"
  },
  {
    "objectID": "data-wrangling/faking.html#generaring-a-uniform-distribution",
    "href": "data-wrangling/faking.html#generaring-a-uniform-distribution",
    "title": "Faking data",
    "section": "",
    "text": "R\n\n\n\nx = runif(n = 1000, min = 0, max = 200)\nboxplot(x)"
  },
  {
    "objectID": "data-wrangling/faking.html#faking-data-for-a-database",
    "href": "data-wrangling/faking.html#faking-data-for-a-database",
    "title": "Faking data",
    "section": "Faking data for a database",
    "text": "Faking data for a database\nFaking data is very useful for populating test databases. In fact, the script below was used to generate the example data with the tables customers, orders, suppliers and products used on this website.\n\nPython\n\n\n\nfrom faker import Faker\nimport pandas as pd\nimport random\n\nfake = Faker()\n\n# Generating customers\nnum_customers = 300\ncustomers = []\nfor _ in range(num_customers):\n    customers.append({\n        'customer_id': fake.uuid4(),\n        'customer_name': fake.name(),\n        'email': fake.email(),\n        'phone_number': fake.phone_number(),\n        'address': fake.address()\n    })\n\n# Generating suppliers\nnum_suppliers = 12\nsuppliers = []\nfor _ in range(num_suppliers):\n    suppliers.append({\n        'supplier_id': fake.uuid4(),\n        'supplier_name': fake.company(),\n        'supplier_email': fake.company_email(),\n        'phone_number': fake.phone_number(),\n        'address': fake.address()\n    })\n\n# Generating products\nnum_products = 30\nproducts = []\nfor i in range(num_products):\n    products.append({\n        'product_id': i + 1,\n        'product_name': fake.word(),\n        'product_description': fake.text(),\n        'price': round(random.uniform(10, 1000), 2),\n        'supplier_id': random.choice(suppliers)['supplier_id']\n    })\n\n# Generating orders\nnum_orders = 500\norders = []\nfor _ in range(num_orders):\n    customer = random.choice(customers)\n    order = {\n        'order_id': fake.uuid4(),\n        'customer_id': customer['customer_id'],\n        'product_id': random.choice(products)['product_id'],\n        'quantity': random.randint(1, 5),\n        'order_date': fake.date_this_year(),\n        'delivery_date': fake.date_between(start_date='today', end_date='+30d')\n    }\n    orders.append(order)\n\n# Creating DataFrames\ncustomers_df = pd.DataFrame(customers)\nsuppliers_df = pd.DataFrame(suppliers)\nproducts_df = pd.DataFrame(products)\norders_df = pd.DataFrame(orders)\n\n# Saving to Excel file\nwith pd.ExcelWriter('db.xlsx', engine='openpyxl') as writer:\n    customers_df.to_excel(writer, sheet_name='Customers', index=False)\n    suppliers_df.to_excel(writer, sheet_name='Suppliers', index=False)\n    products_df.to_excel(writer, sheet_name='Products', index=False)\n    orders_df.to_excel(writer, sheet_name='Orders', index=False)\n    \n\n# Create an SQLite database and establish connection\nconn = sqlite3.connect('db.sqlite')\ncursor = conn.cursor()\n\n# Create tables\ncursor.execute('''\n    CREATE TABLE Customers (\n        customer_id TEXT PRIMARY KEY,\n        customer_name TEXT,\n        email TEXT,\n        phone_number TEXT,\n        address TEXT\n    )\n''')\n\ncursor.execute('''\n    CREATE TABLE Suppliers (\n        supplier_id TEXT PRIMARY KEY,\n        supplier_name TEXT,\n        supplier_email TEXT,\n        phone_number TEXT,\n        address TEXT\n    )\n''')\n\ncursor.execute('''\n    CREATE TABLE Products (\n        product_id INTEGER PRIMARY KEY,\n        product_name TEXT,\n        product_description TEXT,\n        price REAL,\n        supplier_id TEXT,\n        FOREIGN KEY(supplier_id) REFERENCES Suppliers(supplier_id)\n    )\n''')\n\ncursor.execute('''\n    CREATE TABLE Orders (\n        order_id TEXT PRIMARY KEY,\n        customer_id TEXT,\n        product_id INTEGER,\n        quantity INTEGER,\n        order_date TEXT,\n        delivery_date TEXT,\n        FOREIGN KEY(customer_id) REFERENCES Customers(customer_id),\n        FOREIGN KEY(product_id) REFERENCES Products(product_id)\n    )\n''')\n\n# Insert data into tables\ncursor.executemany('''\n    INSERT INTO Customers (customer_id, customer_name, email, phone_number, address)\n    VALUES (:customer_id, :customer_name, :email, :phone_number, :address)\n''', customers)\n\ncursor.executemany('''\n    INSERT INTO Suppliers (supplier_id, supplier_name, supplier_email, phone_number, address)\n    VALUES (:supplier_id, :supplier_name, :supplier_email, :phone_number, :address)\n''', suppliers)\n\ncursor.executemany('''\n    INSERT INTO Products (product_id, product_name, product_description, price, supplier_id)\n    VALUES (:product_id, :product_name, :product_description, :price, :supplier_id)\n''', products)\n\ncursor.executemany('''\n    INSERT INTO Orders (order_id, customer_id, product_id, quantity, order_date, delivery_date)\n    VALUES (:order_id, :customer_id, :product_id, :quantity, :order_date, :delivery_date)\n''', orders)\n\n# Commit changes and close connection\nconn.commit()\nconn.close()"
  },
  {
    "objectID": "data-wrangling/joins.html",
    "href": "data-wrangling/joins.html",
    "title": "Joining",
    "section": "",
    "text": "PythonRSQL\n\n\n\nimport pandas as pd\n\nresult = pd.merge(orders, products, on=\"product_id\", how=\"left\")\nresult = pd.merge(result, customers, on=\"customer_id\", how=\"left\")\nresult[\"tot_price\"] = result[\"price\"] * result[\"quantity\"]\nresult = result[[\"customer_name\", \"product_name\", \"quantity\", \"price\", \"tot_price\"]]\n\nprint(result)\n\n       customer_name product_name  quantity   price  tot_price\n0         Lisa Bates   conference       2.0  572.67    1145.34\n1     Olivia Kaufman         nice       5.0  648.89    3244.45\n2      Jeffrey Barry          day       3.0  874.70    2624.10\n3     Jessica Benson      develop       2.0  520.76    1041.52\n4        Tina Snyder          act       1.0  422.40     422.40\n..               ...          ...       ...     ...        ...\n495  Joshua Anderson     recently       2.0  182.29     364.58\n496  Robert Thornton         free       5.0  396.34    1981.70\n497       Eric Moore         fast       1.0  439.64     439.64\n498    Jaime Mcguire          our       3.0  677.56    2032.68\n499   Kimberly Brown          day       2.0  874.70    1749.40\n\n[500 rows x 5 columns]\n\n\n\n\n\n\n\nresult &lt;- orders %&gt;%\n  left_join(products, by = c(\"product_id\" = \"product_id\")) %&gt;% \n  left_join(customers, by = c(\"customer_id\" = \"customer_id\")) %&gt;%\n  mutate(tot_price = price*quantity) %&gt;% \n  select(customer_name, product_name, quantity, price, tot_price)\n  \nresult\n\n# A tibble: 500 × 5\n   customer_name  product_name quantity price tot_price\n   &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 Lisa Bates     conference          2 573.     1145. \n 2 Olivia Kaufman nice                5 649.     3244. \n 3 Jeffrey Barry  day                 3 875.     2624. \n 4 Jessica Benson develop             2 521.     1042. \n 5 Tina Snyder    act                 1 422.      422. \n 6 Thomas Campos  receive             3 224.      673. \n 7 Thomas Campos  field               1  72.3      72.3\n 8 Jill Price     free                4 396.     1585. \n 9 Debra Solis    recently            4 182.      729. \n10 Rebecca Wilson soon                5 215.     1074. \n# … with 490 more rows\n\n\n\n\n\n\ndf_joined &lt;- df1 %&gt;% left_join(df2, by=c('x1'='x2', 'y1'='y2'))\n\n\n\n\n\nselect \n    customers.customer_name, \n    products.product_name, \n    orders.quantity, \n    products.price, \n    products.price * orders.quantity as tot_price\nfrom orders\nleft join products on orders.product_id = products.product_id\nleft join customers on orders.customer_id = customers.customer_id;\n\n\nDisplaying records 1 - 10\n\n\ncustomer_name\nproduct_name\nquantity\nprice\ntot_price\n\n\n\n\nLisa Bates\nconference\n2\n572.67\n1145.34\n\n\nOlivia Kaufman\nnice\n5\n648.89\n3244.45\n\n\nJeffrey Barry\nday\n3\n874.70\n2624.10\n\n\nJessica Benson\ndevelop\n2\n520.76\n1041.52\n\n\nTina Snyder\nact\n1\n422.40\n422.40\n\n\nThomas Campos\nreceive\n3\n224.33\n672.99\n\n\nThomas Campos\nfield\n1\n72.26\n72.26\n\n\nJill Price\nfree\n4\n396.34\n1585.36\n\n\nDebra Solis\nrecently\n4\n182.29\n729.16\n\n\nRebecca Wilson\nsoon\n5\n214.72\n1073.60"
  },
  {
    "objectID": "data-wrangling/joins.html#left-join",
    "href": "data-wrangling/joins.html#left-join",
    "title": "Joining",
    "section": "",
    "text": "PythonRSQL\n\n\n\nimport pandas as pd\n\nresult = pd.merge(orders, products, on=\"product_id\", how=\"left\")\nresult = pd.merge(result, customers, on=\"customer_id\", how=\"left\")\nresult[\"tot_price\"] = result[\"price\"] * result[\"quantity\"]\nresult = result[[\"customer_name\", \"product_name\", \"quantity\", \"price\", \"tot_price\"]]\n\nprint(result)\n\n       customer_name product_name  quantity   price  tot_price\n0         Lisa Bates   conference       2.0  572.67    1145.34\n1     Olivia Kaufman         nice       5.0  648.89    3244.45\n2      Jeffrey Barry          day       3.0  874.70    2624.10\n3     Jessica Benson      develop       2.0  520.76    1041.52\n4        Tina Snyder          act       1.0  422.40     422.40\n..               ...          ...       ...     ...        ...\n495  Joshua Anderson     recently       2.0  182.29     364.58\n496  Robert Thornton         free       5.0  396.34    1981.70\n497       Eric Moore         fast       1.0  439.64     439.64\n498    Jaime Mcguire          our       3.0  677.56    2032.68\n499   Kimberly Brown          day       2.0  874.70    1749.40\n\n[500 rows x 5 columns]\n\n\n\n\n\n\n\nresult &lt;- orders %&gt;%\n  left_join(products, by = c(\"product_id\" = \"product_id\")) %&gt;% \n  left_join(customers, by = c(\"customer_id\" = \"customer_id\")) %&gt;%\n  mutate(tot_price = price*quantity) %&gt;% \n  select(customer_name, product_name, quantity, price, tot_price)\n  \nresult\n\n# A tibble: 500 × 5\n   customer_name  product_name quantity price tot_price\n   &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 Lisa Bates     conference          2 573.     1145. \n 2 Olivia Kaufman nice                5 649.     3244. \n 3 Jeffrey Barry  day                 3 875.     2624. \n 4 Jessica Benson develop             2 521.     1042. \n 5 Tina Snyder    act                 1 422.      422. \n 6 Thomas Campos  receive             3 224.      673. \n 7 Thomas Campos  field               1  72.3      72.3\n 8 Jill Price     free                4 396.     1585. \n 9 Debra Solis    recently            4 182.      729. \n10 Rebecca Wilson soon                5 215.     1074. \n# … with 490 more rows\n\n\n\n\n\n\ndf_joined &lt;- df1 %&gt;% left_join(df2, by=c('x1'='x2', 'y1'='y2'))\n\n\n\n\n\nselect \n    customers.customer_name, \n    products.product_name, \n    orders.quantity, \n    products.price, \n    products.price * orders.quantity as tot_price\nfrom orders\nleft join products on orders.product_id = products.product_id\nleft join customers on orders.customer_id = customers.customer_id;\n\n\nDisplaying records 1 - 10\n\n\ncustomer_name\nproduct_name\nquantity\nprice\ntot_price\n\n\n\n\nLisa Bates\nconference\n2\n572.67\n1145.34\n\n\nOlivia Kaufman\nnice\n5\n648.89\n3244.45\n\n\nJeffrey Barry\nday\n3\n874.70\n2624.10\n\n\nJessica Benson\ndevelop\n2\n520.76\n1041.52\n\n\nTina Snyder\nact\n1\n422.40\n422.40\n\n\nThomas Campos\nreceive\n3\n224.33\n672.99\n\n\nThomas Campos\nfield\n1\n72.26\n72.26\n\n\nJill Price\nfree\n4\n396.34\n1585.36\n\n\nDebra Solis\nrecently\n4\n182.29\n729.16\n\n\nRebecca Wilson\nsoon\n5\n214.72\n1073.60"
  },
  {
    "objectID": "data-wrangling/altering.html",
    "href": "data-wrangling/altering.html",
    "title": "Altering",
    "section": "",
    "text": "PythonRSQL\n\n\n\nimport pandas as pd\n\n# Assuming customers is your DataFrame\ndf_reordered = customers[['customer_name'] + list(customers.columns.drop('customer_name'))]\ndf_reordered\n\n          customer_name  ...                                            address\n0        Anthony Guerra  ...  963 Regina Bridge Apt. 279\\nPort Richard, NJ 4...\n1      Elizabeth Newton  ...  5745 Gomez Trafficway Suite 809\\nEast Nathanbe...\n2    Gabrielle Chandler  ...  165 Richards Heights Suite 499\\nEllisview, AR ...\n3         Megan Elliott  ...    049 Andrew Drive Apt. 813\\nTurnerside, WI 61461\n4         Kristin James  ...  2048 Derrick Neck Suite 102\\nSouth Stephaniemo...\n..                  ...  ...                                                ...\n295    Gloria Miller MD  ...  02104 Jason Mountain Suite 530\\nWest Marcussta...\n296      Natalie Butler  ...  014 Wheeler Island Suite 192\\nWebsterport, IA ...\n297    Kimberly Johnson  ...        4609 Porter Mill\\nSouth Donaldton, ID 77125\n298     Joshua Trujillo  ...  175 Bush Streets Apt. 625\\nAmandaborough, AK 8...\n299       Alyssa Howard  ...             81103 Colin Mount\\nJamesstad, NV 46158\n\n[300 rows x 5 columns]\n\n\n\n\n\ndf_reordered = customers %&gt;% \n  select(customer_name, everything()) # move name to beginning\ndf_reordered\n\n# A tibble: 300 × 5\n   customer_name      customer_id      email     phone_number   address         \n   &lt;chr&gt;              &lt;chr&gt;            &lt;chr&gt;     &lt;chr&gt;          &lt;chr&gt;           \n 1 Anthony Guerra     8ab2552b-e4c9-4… janet90@… 659.461.7580   \"963 Regina Bri…\n 2 Elizabeth Newton   57a7c826-f022-4… xbentley… 001-555-635-9… \"5745 Gomez Tra…\n 3 Gabrielle Chandler 6ff9e916-8596-4… cjackson… 943-259-6029x… \"165 Richards H…\n 4 Megan Elliott      0706dd55-3603-4… ryan87@e… (668)271-0295… \"049 Andrew Dri…\n 5 Kristin James      aa8662fc-f9c0-4… brooksam… 815-164-7057x… \"2048 Derrick N…\n 6 Tyler Greene       02306791-9603-4… henry78@… 0769607875     \"344 David Port…\n 7 Tammy Schwartz     43976a56-94e0-4… caroltho… (877)554-1860… \"0870 Brandy Ca…\n 8 Sarah Kennedy      ae209764-c4b2-4… kingrobe… 001-784-128-8… \"609 Sean Prair…\n 9 Kevin Hodges       0230e24e-48c2-4… michael7… 001-969-144-3… \"23923 Kenneth …\n10 Nathan Mitchell    6f7a4a4e-a87a-4… williams… 085.010.4067x… \"053 Bradley Cr…\n# … with 290 more rows\n\n\n\n\n\nSELECT\n  customer_name, -- just choose the order in the select statement\n  customer_id,\n  email,\n  phone_number\nFROM \n  customers;\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\ncustomer_name\ncustomer_id\nemail\nphone_number\n\n\n\n\nAnthony Guerra\n8ab2552b-e4c9-471d-bdf1-ff6e225860e1\njanet90@example.net\n659.461.7580\n\n\nElizabeth Newton\n57a7c826-f022-4f6c-9a21-81d5f99da142\nxbentley@example.com\n001-555-635-9586x3938\n\n\nGabrielle Chandler\n6ff9e916-8596-4fc6-a224-fd1a6e163837\ncjackson@example.net\n943-259-6029x806\n\n\nMegan Elliott\n0706dd55-3603-4985-8136-76872925d39c\nryan87@example.com\n(668)271-0295x004\n\n\nKristin James\naa8662fc-f9c0-4e56-a498-693df376020a\nbrooksamber@example.com\n815-164-7057x78004\n\n\nTyler Greene\n02306791-9603-4a34-b4c8-e6a7019fbe7f\nhenry78@example.net\n0769607875\n\n\nTammy Schwartz\n43976a56-94e0-4769-b7e8-c9f15d4a8511\ncarolthomas@example.org\n(877)554-1860x64446\n\n\nSarah Kennedy\nae209764-c4b2-4c27-82f7-d41f7e71aded\nkingrobert@example.net\n001-784-128-8396\n\n\nKevin Hodges\n0230e24e-48c2-44ec-bbe8-f6aff9029bed\nmichael74@example.org\n001-969-144-3784\n\n\nNathan Mitchell\n6f7a4a4e-a87a-4f6d-927f-a8e2978b00a7\nwilliamsrussell@example.net\n085.010.4067x31103"
  },
  {
    "objectID": "data-wrangling/altering.html#move-columns",
    "href": "data-wrangling/altering.html#move-columns",
    "title": "Altering",
    "section": "",
    "text": "PythonRSQL\n\n\n\nimport pandas as pd\n\n# Assuming customers is your DataFrame\ndf_reordered = customers[['customer_name'] + list(customers.columns.drop('customer_name'))]\ndf_reordered\n\n          customer_name  ...                                            address\n0        Anthony Guerra  ...  963 Regina Bridge Apt. 279\\nPort Richard, NJ 4...\n1      Elizabeth Newton  ...  5745 Gomez Trafficway Suite 809\\nEast Nathanbe...\n2    Gabrielle Chandler  ...  165 Richards Heights Suite 499\\nEllisview, AR ...\n3         Megan Elliott  ...    049 Andrew Drive Apt. 813\\nTurnerside, WI 61461\n4         Kristin James  ...  2048 Derrick Neck Suite 102\\nSouth Stephaniemo...\n..                  ...  ...                                                ...\n295    Gloria Miller MD  ...  02104 Jason Mountain Suite 530\\nWest Marcussta...\n296      Natalie Butler  ...  014 Wheeler Island Suite 192\\nWebsterport, IA ...\n297    Kimberly Johnson  ...        4609 Porter Mill\\nSouth Donaldton, ID 77125\n298     Joshua Trujillo  ...  175 Bush Streets Apt. 625\\nAmandaborough, AK 8...\n299       Alyssa Howard  ...             81103 Colin Mount\\nJamesstad, NV 46158\n\n[300 rows x 5 columns]\n\n\n\n\n\ndf_reordered = customers %&gt;% \n  select(customer_name, everything()) # move name to beginning\ndf_reordered\n\n# A tibble: 300 × 5\n   customer_name      customer_id      email     phone_number   address         \n   &lt;chr&gt;              &lt;chr&gt;            &lt;chr&gt;     &lt;chr&gt;          &lt;chr&gt;           \n 1 Anthony Guerra     8ab2552b-e4c9-4… janet90@… 659.461.7580   \"963 Regina Bri…\n 2 Elizabeth Newton   57a7c826-f022-4… xbentley… 001-555-635-9… \"5745 Gomez Tra…\n 3 Gabrielle Chandler 6ff9e916-8596-4… cjackson… 943-259-6029x… \"165 Richards H…\n 4 Megan Elliott      0706dd55-3603-4… ryan87@e… (668)271-0295… \"049 Andrew Dri…\n 5 Kristin James      aa8662fc-f9c0-4… brooksam… 815-164-7057x… \"2048 Derrick N…\n 6 Tyler Greene       02306791-9603-4… henry78@… 0769607875     \"344 David Port…\n 7 Tammy Schwartz     43976a56-94e0-4… caroltho… (877)554-1860… \"0870 Brandy Ca…\n 8 Sarah Kennedy      ae209764-c4b2-4… kingrobe… 001-784-128-8… \"609 Sean Prair…\n 9 Kevin Hodges       0230e24e-48c2-4… michael7… 001-969-144-3… \"23923 Kenneth …\n10 Nathan Mitchell    6f7a4a4e-a87a-4… williams… 085.010.4067x… \"053 Bradley Cr…\n# … with 290 more rows\n\n\n\n\n\nSELECT\n  customer_name, -- just choose the order in the select statement\n  customer_id,\n  email,\n  phone_number\nFROM \n  customers;\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\ncustomer_name\ncustomer_id\nemail\nphone_number\n\n\n\n\nAnthony Guerra\n8ab2552b-e4c9-471d-bdf1-ff6e225860e1\njanet90@example.net\n659.461.7580\n\n\nElizabeth Newton\n57a7c826-f022-4f6c-9a21-81d5f99da142\nxbentley@example.com\n001-555-635-9586x3938\n\n\nGabrielle Chandler\n6ff9e916-8596-4fc6-a224-fd1a6e163837\ncjackson@example.net\n943-259-6029x806\n\n\nMegan Elliott\n0706dd55-3603-4985-8136-76872925d39c\nryan87@example.com\n(668)271-0295x004\n\n\nKristin James\naa8662fc-f9c0-4e56-a498-693df376020a\nbrooksamber@example.com\n815-164-7057x78004\n\n\nTyler Greene\n02306791-9603-4a34-b4c8-e6a7019fbe7f\nhenry78@example.net\n0769607875\n\n\nTammy Schwartz\n43976a56-94e0-4769-b7e8-c9f15d4a8511\ncarolthomas@example.org\n(877)554-1860x64446\n\n\nSarah Kennedy\nae209764-c4b2-4c27-82f7-d41f7e71aded\nkingrobert@example.net\n001-784-128-8396\n\n\nKevin Hodges\n0230e24e-48c2-44ec-bbe8-f6aff9029bed\nmichael74@example.org\n001-969-144-3784\n\n\nNathan Mitchell\n6f7a4a4e-a87a-4f6d-927f-a8e2978b00a7\nwilliamsrussell@example.net\n085.010.4067x31103"
  },
  {
    "objectID": "data-wrangling/choices.html",
    "href": "data-wrangling/choices.html",
    "title": "Choices",
    "section": "",
    "text": "Choices enable you to run different code based on conditions / input. The most basic form of choices is the if statement.\n\nPythonRSQL\n\n\n\nz = 4\nif z % 2 == 0:\n    print(\"z is even\")\nelse:\n    print(\"z is uneven\")\n\nz is even\n\n\n\n\nin one line\n\nz = 4\nif (z %% 2 == 0) print(\"z is even\") else print(\"z is odd\")\n\n[1] \"z is even\"\n\n\nin several lines\n\nz = 5\nif (z %% 2 == 0) {\n  print(\"z is even\")\n} else {\n  print(\"z is odd\")\n}\n\n[1] \"z is odd\"\n\n\n\n\nNote, that SQLite does not support the “normal” if statement. However, the same can be achieved with the case when statement.\n\n-- SQLite flavor\nselect\n  price\n  ,  case when price &gt;= 500 then 'high-price' else 'low-price' end as price_categ\nfrom\n  (select 750 as price)\nlimit 5;\n\n\n1 records\n\n\nprice\nprice_categ\n\n\n\n\n750\nhigh-price"
  },
  {
    "objectID": "data-wrangling/choices.html#the-if-statement",
    "href": "data-wrangling/choices.html#the-if-statement",
    "title": "Choices",
    "section": "",
    "text": "Choices enable you to run different code based on conditions / input. The most basic form of choices is the if statement.\n\nPythonRSQL\n\n\n\nz = 4\nif z % 2 == 0:\n    print(\"z is even\")\nelse:\n    print(\"z is uneven\")\n\nz is even\n\n\n\n\nin one line\n\nz = 4\nif (z %% 2 == 0) print(\"z is even\") else print(\"z is odd\")\n\n[1] \"z is even\"\n\n\nin several lines\n\nz = 5\nif (z %% 2 == 0) {\n  print(\"z is even\")\n} else {\n  print(\"z is odd\")\n}\n\n[1] \"z is odd\"\n\n\n\n\nNote, that SQLite does not support the “normal” if statement. However, the same can be achieved with the case when statement.\n\n-- SQLite flavor\nselect\n  price\n  ,  case when price &gt;= 500 then 'high-price' else 'low-price' end as price_categ\nfrom\n  (select 750 as price)\nlimit 5;\n\n\n1 records\n\n\nprice\nprice_categ\n\n\n\n\n750\nhigh-price"
  },
  {
    "objectID": "data-wrangling/choices.html#the-elif-statement",
    "href": "data-wrangling/choices.html#the-elif-statement",
    "title": "Choices",
    "section": "The elif statement",
    "text": "The elif statement\nFor more complex choices, the elif or else if statement can be used.\n\n\n\n\n\n\nCaution\n\n\n\nKeep in mind, that only the line of code in the first true condition will run. The order of conditions matters!\n\n\n\nPythonRSQL\n\n\n\ndef get_price_categ(price):\n  categ = str()\n  if price &gt; 1000:\n    categ = \"high\"\n  elif price &gt; 700:\n    categ = \"middle\"\n  elif price &gt; 300:\n    categ = \"low\"\n  elif price &gt; 0:\n    categ = \"super cheap\"\n  elif price == 0:\n    categ = \"free\"\n  else:\n    categ = \"there must be an error\"\n  return categ\n\nget_price_categ(750)  \n\n'middle'\n\n\n\n\nThe if in R works specifically or scalars.\n\nget_price_categ &lt;- function(price) {\n  categ &lt;- character()\n  if (price &gt; 1000) {\n    categ &lt;- \"high\"\n  } else if (price &gt; 700) {\n    categ &lt;- \"middle\"\n  } else if (price &gt; 300) {\n    categ &lt;- \"low\"\n  } else if (price &gt; 0) {\n    categ &lt;- \"super cheap\"\n  } else if (price == 0) {\n    categ &lt;- \"free\"\n  } else {\n    categ &lt;- \"there must be an error\"\n  }\n  return(categ)\n}\n\nget_price_categ(17)\n\n[1] \"super cheap\"\n\n\n\n\nNote, that many SQL flavors do not have a classic elif, but the case when can be used as an elif like the following:\n\n-- SQLite flavor\nselect \n  price,\n  case \n    when price &gt; 1000 then 'high'\n    when price &gt; 700 then 'middle'\n    when price &gt; 300 then 'low'\n    when price &gt; 0 then 'super cheap'\n    when price = 0 then 'free'\n    else 'there must be an error'\n  end as price_category\nfrom\n  (select 750 as price) as subquery;\n\n\n1 records\n\n\nprice\nprice_category\n\n\n\n\n750\nmiddle"
  },
  {
    "objectID": "data-wrangling/choices.html#the-if-elif-case-when-statement-for-vectors-columns",
    "href": "data-wrangling/choices.html#the-if-elif-case-when-statement-for-vectors-columns",
    "title": "Choices",
    "section": "The if / elif / case when statement for vectors / columns",
    "text": "The if / elif / case when statement for vectors / columns\nA classic task in data cleaning is changing the values of a column in a df to a different value, based on conditions.\n\nPythonRSQL\n\n\n\nimport pandas as pd\n\ndf = orders[['quantity']].copy()\ndf['order_size'] = df['quantity'].apply(lambda x: 'large' if x &gt;= 3 else 'small')\ndf = df.iloc[0:5]\n\nprint(df)\n\n\n\nThe ifelse in R works specifically for vectors.\n\ndf &lt;- orders %&gt;% \n  select(quantity) %&gt;% \n  mutate(order_size = ifelse(quantity &gt; 3, \"large\", \"small\")) %&gt;% \n  slice(1:5)\ndf\n\n# A tibble: 5 × 2\n  quantity order_size\n     &lt;dbl&gt; &lt;chr&gt;     \n1        2 small     \n2        5 large     \n3        3 small     \n4        2 small     \n5        1 small     \n\n\nFor more conditions, the dplyr::case_when feels more natural and improves readability, especially when having several conditions\n\ndf &lt;- orders %&gt;%\n  select(quantity) %&gt;% \n  mutate(\n    quantity_categ = case_when(\n      quantity == 1 ~ \"small\",\n      quantity %in% c(2, 3) ~ \"middle\",\n      quantity &gt; 3 ~ \"large\",\n      TRUE ~ \"there must be sth wrong\" # this line is like an \"else\"\n    )\n  ) %&gt;% \n  slice(1:5)\ndf\n\n# A tibble: 5 × 2\n  quantity quantity_categ\n     &lt;dbl&gt; &lt;chr&gt;         \n1        2 middle        \n2        5 large         \n3        3 middle        \n4        2 middle        \n5        1 small         \n\n\n\n\n\n-- SQLite flavor\nselect quantity,\n    case\n        when quantity = 1 then 'small'\n        when quantity IN (2, 3) then 'middle'\n        when quantity &gt; 3 then 'large'\n        else 'there must be sth wrong'\n    end as quantity_categ\nfrom orders\nlimit 5;\n\n\n5 records\n\n\nquantity\nquantity_categ\n\n\n\n\n2\nmiddle\n\n\n5\nlarge\n\n\n3\nmiddle\n\n\n2\nmiddle\n\n\n1\nsmall"
  },
  {
    "objectID": "data-wrangling/choices.html#working-with-and-and-or",
    "href": "data-wrangling/choices.html#working-with-and-and-or",
    "title": "Choices",
    "section": "Working with and and or",
    "text": "Working with and and or\nFor more complex choices, where several combinations of conditions are necessary, the conditions are comibned using and, or and brackets to group conditions together.\n\nPythonRSQL\n\n\n\n# Sample data\nage = 25\nincome = 35000\nstudent = True\n\n# Logical conditions\nis_young_adult = 18 &lt;= age &lt;= 30    # Age between 18 and 30\nhas_low_income = income &lt; 30000             # Income below 30,000\nis_student = student                       # Is a student\n\n# Combining conditions with 'and', 'or', and brackets\nif is_young_adult and (has_low_income or is_student):\n    print(\"Financial support applicable\")\nelse:\n    print(\"Financial support not applicable\")\n\nFinancial support applicable\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor performance improvement, it may be useful to use && instead of &. The && operator will only run the condition(s) on the right handside, if the condition on the left handside is TRUE, saving unnecessary computaion.\n\n\n\n# Sample data\nage &lt;- 25\nincome &lt;- 35000\nstudent &lt;- TRUE\n\n# Logical conditions\nis_young_adult &lt;- age &gt;= 18 & age &lt;= 30   # Age between 18 and 30\nhas_low_income &lt;- income &lt; 30000          # Income below 30,000\nis_student &lt;- student                     # Is a student\n\n# Combining conditions with 'and', 'or', and brackets\nif (is_young_adult & (has_low_income | is_student)) {\n  print(\"Financial support applicable\")\n} else {\n  print(\"Financial support not applicable\")\n}\n\n[1] \"Financial support applicable\"\n\n\n\n\n\n-- sample data\nwith data as (\n  select 25 as age, 35000 as income, 1 as student\n)\n-- conditional logic using case statement\nselect\n  case\n    when age &gt;= 18 and age &lt;= 30 and (income &lt; 30000 or student = 1) then 'financial support applicable'\n    else 'financial support not applicable'\n    end as support_status\nfrom\n  data;\n\n\n1 records\n\n\nsupport_status\n\n\n\n\nfinancial support applicable"
  },
  {
    "objectID": "data-wrangling/choices.html#the-switch-statement",
    "href": "data-wrangling/choices.html#the-switch-statement",
    "title": "Choices",
    "section": "The switch statement",
    "text": "The switch statement\nThe switch statement is especially useful for getting values from a dictionary-like construct with key and value.\n\nR\n\n\n\nget_height &lt;- function(x) {\n  switch(x,\n    \"eiffel tower\" = 330,\n    \"Burj Khalifa\" = 828,\n    \"Shanghai Tower\" = 632,\n    stop(\"not found\") # always include a \"not found\" for debugging purposes\n  )\n}\nget_height(\"Shanghai Tower\")\n\n[1] 632"
  },
  {
    "objectID": "data-wrangling/window_functions.html",
    "href": "data-wrangling/window_functions.html",
    "title": "Window functions",
    "section": "",
    "text": "For advanced queries, window functions are very useful to perform calculations based on partition, order and function in a set of rows. They allow to put the current row into context with other rows and perform tasks such as ranking, aggregating, and using analytic functions.\n\n\n\nRanking Functions: Assign e.g. a row number or a rank to a row based on defined criteria. Examples are rank, dense_rank, row_number etc.\nAggregate Functions: Aggregate values over the defined partition avg, sum, count.\nAnalytic Functions: Operate on a range of rows around the current row. Examples are lead, lag, first_value, last_value, nth_value, ntile etc.\n\nAs always, an example says more than a thousand words:"
  },
  {
    "objectID": "data-wrangling/window_functions.html#introduction",
    "href": "data-wrangling/window_functions.html#introduction",
    "title": "Window functions",
    "section": "",
    "text": "For advanced queries, window functions are very useful to perform calculations based on partition, order and function in a set of rows. They allow to put the current row into context with other rows and perform tasks such as ranking, aggregating, and using analytic functions.\n\n\n\nRanking Functions: Assign e.g. a row number or a rank to a row based on defined criteria. Examples are rank, dense_rank, row_number etc.\nAggregate Functions: Aggregate values over the defined partition avg, sum, count.\nAnalytic Functions: Operate on a range of rows around the current row. Examples are lead, lag, first_value, last_value, nth_value, ntile etc.\n\nAs always, an example says more than a thousand words:"
  },
  {
    "objectID": "data-wrangling/window_functions.html#ranking-functions",
    "href": "data-wrangling/window_functions.html#ranking-functions",
    "title": "Window functions",
    "section": "Ranking Functions",
    "text": "Ranking Functions\nAt first glance, it may seem, that the ranking functions all produce the same results. When taking a closer look we notice, that there are slight differences. The row_number will assign a unique value to each row in the window, whereas rank will assign the same value for the same criteria; as in the example below, if there were two values of total_cost that were exactly the same within the window, the rank function would assign the same value (e.g. both 2) and then skip one value (i.e. skip 3 and proceed with 4). The dense_rank is like the rank but without skipping the preceding value.\n\nSQLPythonR\n\n\n\nwith sales as (\n  select\n    c.customer_name  \n    , p.product_name\n    , p.price\n    , o.quantity\n    , p.price * o.quantity as total_cost\n    , order_date\n    , strftime('%Y', order_date) || '-' || strftime('%W', order_date) as yyyy_ww\n    \n  from \n    orders as o\n  inner join products as p on\n    p.product_id = o.product_id\n  inner join customers as c on\n   c.customer_id = o.customer_id\n)\n\nselect\n  *\n  , row_number() over(partition by yyyy_ww order by price desc) as rn\n  , rank() over(partition by yyyy_ww order by price desc) as rank\n  , dense_rank() over(partition by yyyy_ww order by price desc) as dense_rank\nfrom\n  sales\norder by\n  yyyy_ww asc, rn asc\nlimit 15 offset 4;\n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncustomer_name\nproduct_name\nprice\nquantity\ntotal_cost\norder_date\nyyyy_ww\nrn\nrank\ndense_rank\n\n\n\n\nChristine Holt\nact\n422.40\n3\n1267.20\n2023-01-05\n2023-01\n3\n3\n3\n\n\nJodi Brown\nteach\n245.39\n3\n736.17\n2023-01-03\n2023-01\n4\n4\n4\n\n\nDanny Rodriguez\ndrive\n162.04\n4\n648.16\n2023-01-06\n2023-01\n5\n5\n5\n\n\nEric Davis\nrecent\n135.03\n1\n135.03\n2023-01-05\n2023-01\n6\n6\n6\n\n\nRobert Strickland\nwe\n119.74\n1\n119.74\n2023-01-06\n2023-01\n7\n7\n7\n\n\nBrittany Johnson\nthere\n912.52\n1\n912.52\n2023-01-09\n2023-02\n1\n1\n1\n\n\nSarah Kennedy\nthere\n912.52\n4\n3650.08\n2023-01-12\n2023-02\n2\n1\n1\n\n\nTerry Morgan\nthere\n912.52\n4\n3650.08\n2023-01-10\n2023-02\n3\n1\n1\n\n\nAmanda Johnson\nable\n730.41\n3\n2191.23\n2023-01-10\n2023-02\n4\n4\n2\n\n\nRobert Strickland\ntravel\n666.50\n2\n1333.00\n2023-01-09\n2023-02\n5\n5\n3\n\n\n\n\n\n\n\n\nimport pandas as pd\n\nmerged_df = pd.merge(orders, products, how='inner', on='product_id')\nmerged_df = pd.merge(merged_df, customers, how='inner', on='customer_id')\n\n# Calculating total_cost and yyyy_ww\nmerged_df['total_cost'] = merged_df['price'] * merged_df['quantity']\nmerged_df['yyyy_ww'] = merged_df['order_date'].dt.strftime('%Y-%W')\n\nmerged_df['rn'] = merged_df.groupby('yyyy_ww')['price'].transform(lambda x: x.rank(method='first', ascending=False))\nmerged_df['rank'] = merged_df.groupby('yyyy_ww')['price'].rank(method='min', ascending=False)\nmerged_df['dense_rank'] = merged_df.groupby('yyyy_ww')['price'].rank(method='dense', ascending=False)\n\n# Selecting specific columns\nselected_columns = [\n    'customer_name', 'product_name', 'price', 'quantity', 'order_date',\n    'rn', 'rank', 'dense_rank'\n]\n\nresult_df = merged_df.sort_values(by=['yyyy_ww', 'rn']).head(15)[selected_columns].iloc[4:15]\n\nprint(result_df)\n\n         customer_name product_name   price  ...   rn rank  dense_rank\n191     Christine Holt          act  422.40  ...  3.0  3.0         3.0\n94          Jodi Brown        teach  245.39  ...  4.0  4.0         4.0\n336    Danny Rodriguez        drive  162.04  ...  5.0  5.0         5.0\n474         Eric Davis       recent  135.03  ...  6.0  6.0         6.0\n398  Robert Strickland           we  119.74  ...  7.0  7.0         7.0\n105       Terry Morgan        there  912.52  ...  1.0  1.0         1.0\n159      Sarah Kennedy        there  912.52  ...  2.0  1.0         1.0\n331   Brittany Johnson        there  912.52  ...  3.0  1.0         1.0\n416     Amanda Johnson         able  730.41  ...  4.0  4.0         2.0\n401  Robert Strickland       travel  666.50  ...  5.0  5.0         3.0\n344       Aaron Miller         must  657.16  ...  6.0  6.0         4.0\n\n[11 rows x 8 columns]\n\n\n\n\n\nlibrary(dplyr)\nlibrary(tidyr)\n\nsales &lt;- orders %&gt;%\n  inner_join(products, by = \"product_id\") %&gt;%\n  inner_join(customers, by = \"customer_id\") %&gt;%\n  mutate(\n    total_cost = price * quantity,\n    yyyy_ww = paste0(strftime(order_date, \"%Y\"), \"-\", strftime(order_date, \"%W\"))\n  )\n\nsales &lt;- sales %&gt;%\n  arrange(yyyy_ww, desc(price)) %&gt;%\n  group_by(yyyy_ww) %&gt;%\n  mutate(\n    rn = row_number(desc(price)),\n    rank = rank(desc(price)),\n    dense_rank = dense_rank(desc(price))\n  ) %&gt;%\n  ungroup() %&gt;% # dplyr uses the ungroup() as pendant to window functions\n  select( rn, rank, dense_rank, customer_name, product_name,\n          price, quantity, order_date,\n  ) %&gt;%\n  slice(5:15)\nsales\n\n# A tibble: 11 × 8\n      rn  rank dense_rank customer_name     product_name price quantity\n   &lt;int&gt; &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1     3     3          3 Christine Holt    act           422.        3\n 2     4     4          4 Jodi Brown        teach         245.        3\n 3     5     5          5 Danny Rodriguez   drive         162.        4\n 4     6     6          6 Eric Davis        recent        135.        1\n 5     7     7          7 Robert Strickland we            120.        1\n 6     1     2          1 Brittany Johnson  there         913.        1\n 7     2     2          1 Sarah Kennedy     there         913.        4\n 8     3     2          1 Terry Morgan      there         913.        4\n 9     4     4          2 Amanda Johnson    able          730.        3\n10     5     5          3 Robert Strickland travel        666.        2\n11     6     6          4 Aaron Miller      must          657.        5\n# … with 1 more variable: order_date &lt;dttm&gt;"
  },
  {
    "objectID": "data-wrangling/window_functions.html#aggregating-functions",
    "href": "data-wrangling/window_functions.html#aggregating-functions",
    "title": "Window functions",
    "section": "Aggregating Functions",
    "text": "Aggregating Functions\nThey are very useful to aggregate data on specified criteria using a window. The window can be aggregated using the partition clause and ordered by the order clause. Finally, a window can be set using rows between X preceding and Y following with X and Y being integers or unbounded, if we want the window to start from start to the end. It is also possible to set a range instead of rows\n\nSQLPythonR\n\n\n\nwith sales as (\n  select\n    c.customer_id\n    , p.product_name\n    , p.price\n    , o.quantity\n    , p.price * o.quantity as total_cost\n    , order_date\n  from \n    orders as o\n  inner join products as p on\n    p.product_id = o.product_id\n  inner join customers as c on\n    c.customer_id = o.customer_id\n)\n\nselect\n  *\n  , avg(total_cost) over(order by order_date rows between 1 preceding and 1 following) as avg_3_rows\n  , sum(total_cost) over(order by order_date rows unbounded preceding) as running_sum\n  , count() over(partition by customer_id) as orders_per_cust\nfrom\n  sales\norder by\n  order_date\n  \n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\n\n\n\n\n\n\ncustomer_id\nproduct_name\nprice\nquantity\ntotal_cost\norder_date\navg_3_rows\nrunning_sum\norders_per_cust\n\n\n\n\n0b18417b-543d-429c-a468-1592aea8c1a2\nconference\n572.67\n4\n2290.68\n2023-01-01\n1539.9650\n2290.68\n3\n\n\n0e683879-4049-4382-b977-965a06daa874\nauthor\n789.25\n1\n789.25\n2023-01-01\n1272.0333\n3079.93\n2\n\n\nc9b595f2-b44b-4b02-ad87-1fba8404074d\nteach\n245.39\n3\n736.17\n2023-01-03\n1091.6067\n3816.10\n3\n\n\nc9b595f2-b44b-4b02-ad87-1fba8404074d\nday\n874.70\n2\n1749.40\n2023-01-04\n873.5333\n5565.50\n3\n\n\n2c1823ce-2ca8-440f-8b47-d00873dd6e2c\nrecent\n135.03\n1\n135.03\n2023-01-05\n1050.5433\n5700.53\n2\n\n\ne3c0eb04-ba9b-4fe5-89b2-d099e193d04d\nact\n422.40\n3\n1267.20\n2023-01-05\n507.3233\n6967.73\n2\n\n\n6680325a-df9b-407c-b3d1-0a19a96ca118\nwe\n119.74\n1\n119.74\n2023-01-06\n678.3667\n7087.47\n4\n\n\nb7887f71-9683-470a-8718-68c49cb4bb18\ndrive\n162.04\n4\n648.16\n2023-01-06\n402.5133\n7735.63\n2\n\n\n0e683879-4049-4382-b977-965a06daa874\nfast\n439.64\n1\n439.64\n2023-01-08\n806.9333\n8175.27\n2\n\n\n6680325a-df9b-407c-b3d1-0a19a96ca118\ntravel\n666.50\n2\n1333.00\n2023-01-09\n1686.1467\n9508.27\n4\n\n\n\n\n\n\n\n\nimport pandas as pd\n\nsales = pd.merge(orders, products, on='product_id').merge(customers, on='customer_id')\nsales['total_cost'] = sales['price'] * sales['quantity']\nsales = sales.sort_values('order_date')\nsales['avg_3_rows'] = sales['total_cost'].rolling(window=3, min_periods=1).mean()\nsales['running_sum'] = sales['total_cost'].cumsum()\nsales['orders_per_cust'] = sales.groupby('customer_id')['customer_id'].transform('count')\nresult = sales[['customer_id', 'product_name', 'price', 'quantity', 'total_cost', 'order_date', 'avg_3_rows', 'running_sum', 'orders_per_cust']]\nresult = result.sort_values('order_date').reset_index(drop=True)\nprint(result)\n\n                              customer_id  ... orders_per_cust\n0    0b18417b-543d-429c-a468-1592aea8c1a2  ...               3\n1    0e683879-4049-4382-b977-965a06daa874  ...               2\n2    c9b595f2-b44b-4b02-ad87-1fba8404074d  ...               3\n3    c9b595f2-b44b-4b02-ad87-1fba8404074d  ...               3\n4    e3c0eb04-ba9b-4fe5-89b2-d099e193d04d  ...               2\n..                                    ...  ...             ...\n495  5b4e2a6e-dab7-415b-badb-1e4ef26155ac  ...               4\n496  96e4be4c-42a3-4f62-ba5d-46a022883c83  ...               1\n497  b0f2cebf-a461-4135-886a-10e97cc2dac6  ...               3\n498  fd6d1332-e821-4d2b-87e0-2dc1c7d734e7  ...               2\n499  0b6bc6fb-4e69-4fe0-8bd4-aee20da0116b  ...               1\n\n[500 rows x 9 columns]\n\n\n\n\nNote that the results around the first and last rows may differ compared to the sql junk, since the window functions are differently implemented in sql and R.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.6     ✔ stringr 1.4.0\n✔ readr   2.1.0     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ purrr::modify() masks renv::modify()\n\nlibrary(slider)\n\nsales &lt;- orders %&gt;%\n  inner_join(products, by = \"product_id\") %&gt;%\n  inner_join(customers, by = \"customer_id\") %&gt;%\n  mutate(total_cost = price * quantity) %&gt;% \n  select(\n    customer_id,\n    product_name,\n    price,\n    quantity,\n    total_cost,\n    order_date\n  )\n\nresult &lt;- sales %&gt;%\n  arrange(order_date) %&gt;%\n  mutate(\n    avg_3_rows = slide_dbl(total_cost, mean, .before = 1, .after = 1, .complete = TRUE),\n    running_sum = cumsum(total_cost),\n    orders_per_cust = n()\n  ) %&gt;%\n  group_by(customer_id) %&gt;%\n  mutate(\n    orders_per_cust = n()\n  ) %&gt;%\n  ungroup() %&gt;%\n  arrange(order_date)\n\nresult\n\n# A tibble: 500 × 9\n   customer_id        product_name price quantity total_cost order_date         \n   &lt;chr&gt;              &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;dttm&gt;             \n 1 0b18417b-543d-429… conference    573.        4      2291. 2023-01-01 00:00:00\n 2 0e683879-4049-438… author        789.        1       789. 2023-01-01 00:00:00\n 3 c9b595f2-b44b-4b0… teach         245.        3       736. 2023-01-03 00:00:00\n 4 c9b595f2-b44b-4b0… day           875.        2      1749. 2023-01-04 00:00:00\n 5 2c1823ce-2ca8-440… recent        135.        1       135. 2023-01-05 00:00:00\n 6 e3c0eb04-ba9b-4fe… act           422.        3      1267. 2023-01-05 00:00:00\n 7 6680325a-df9b-407… we            120.        1       120. 2023-01-06 00:00:00\n 8 b7887f71-9683-470… drive         162.        4       648. 2023-01-06 00:00:00\n 9 0e683879-4049-438… fast          440.        1       440. 2023-01-08 00:00:00\n10 e32da01f-81f0-4da… there         913.        1       913. 2023-01-09 00:00:00\n# … with 490 more rows, and 3 more variables: avg_3_rows &lt;dbl&gt;,\n#   running_sum &lt;dbl&gt;, orders_per_cust &lt;int&gt;"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to coding-snippet",
    "section": "",
    "text": "Welcome to coding-snippet! We offer an open source collection of data science snippets in various programming languages like Python, R and SQL that are relevant for data-related problems. Our platform is specifically designed for data enthusiasts who are tired of scanning the internet over and over again for the very same code snippets they use in their daily data analysis tasks.\n\n\n\nCurated Code Snippets: We documented a wide range of code snippets for problems that come across a data analyst’s / data scientist’s work day all the time. Copy, paste and adjust the snippets according to your problem.\nProblem Oriented Approach: As data scientists, we jump between coding and query languages all the time; writing a database query in SQL, adding another data source from a python-based web-scraper and visualizing the beautifully aggregated data as a plot in R ggplot. We noticed, that most coders document their snippets in a language oriented manner, having e.g. one document per language. We believe in the problem oriented approach, where the snippets are organized according to the problem.\nPlatform for Collaboration: Become a collaborator on our Github repository and contribute to improving the quality and amount of the coding snippet base. We value your input and are always open for constructive criticism.\n\n\n\n\nWe believe, that a well-organized documentation of the different problems and tools helps the data science community to work more efficiently and helps rookies to get started much faster. Feel free for reaching out to us for an informal (virtual or in-person) coffee.\n\n\n\nFind us online and on LinkedIn for the latest updates, discussions, and insights.\nThank you for taking part in our community and sharing our knowledge base with others!"
  },
  {
    "objectID": "index.html#about-us",
    "href": "index.html#about-us",
    "title": "Welcome to coding-snippet",
    "section": "",
    "text": "Welcome to coding-snippet! We offer an open source collection of data science snippets in various programming languages like Python, R and SQL that are relevant for data-related problems. Our platform is specifically designed for data enthusiasts who are tired of scanning the internet over and over again for the very same code snippets they use in their daily data analysis tasks.\n\n\n\nCurated Code Snippets: We documented a wide range of code snippets for problems that come across a data analyst’s / data scientist’s work day all the time. Copy, paste and adjust the snippets according to your problem.\nProblem Oriented Approach: As data scientists, we jump between coding and query languages all the time; writing a database query in SQL, adding another data source from a python-based web-scraper and visualizing the beautifully aggregated data as a plot in R ggplot. We noticed, that most coders document their snippets in a language oriented manner, having e.g. one document per language. We believe in the problem oriented approach, where the snippets are organized according to the problem.\nPlatform for Collaboration: Become a collaborator on our Github repository and contribute to improving the quality and amount of the coding snippet base. We value your input and are always open for constructive criticism.\n\n\n\n\nWe believe, that a well-organized documentation of the different problems and tools helps the data science community to work more efficiently and helps rookies to get started much faster. Feel free for reaching out to us for an informal (virtual or in-person) coffee.\n\n\n\nFind us online and on LinkedIn for the latest updates, discussions, and insights.\nThank you for taking part in our community and sharing our knowledge base with others!"
  }
]